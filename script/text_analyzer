#!/usr/bin/env ruby

# use: 
#         rails runner script/text_analyzer


# text_analyzer is a consumer of the analysis queue.
# Consuming a message consists of pulling all tweets from the database with the given twitter handle,
# And calling the text_analyzer.py which wraps the python NLTK (natural language toolkit)

# yes, this is a hack
ActiveRecord::Base


def preprocess_tweet(tweet)
  tweet.gsub(/\bhttp:\/\/.+\..+(\/.+?)?\b/, '').gsub(/[^A-Za-z\-\ ]|RT/, '').gsub(/\-/, '\-').gsub(/\s+/, ' ')
end


# where the script is running
cwd = File.expand_path File.dirname(__FILE__)

connection_handler = Proc.new { |settings| puts "Failed to connect to broker"; EventMachine.stop }
channel_exception_handler = Proc.new { |ch, channel_close| EventMachine.stop; raise "channel error: #{channel_close.reply_text}" }
connection_settings = {
  :host => QueueMaster.host,
  :on_tcp_connection_failure => connection_handler,
  :timeout => 1
}

# start the main event loop
AMQP.start(connection_settings) do |connection|
  puts 'Opening connection to broker'

  # create our channel
  channel = AMQP::Channel.new(connection, :auto_recovery => true)
  channel.on_error(&channel_exception_handler)
  # only process messages one-by-one
  channel.prefetch(2)

  channel.queue('text_analyzer.queue', :durable => true, :auto_delete => false) do |queue|

    puts 'subscribing to messages'
    queue.bind(QueueMaster::ANALYSIS_EXCHANGE).subscribe(:ack => true) do |metadata, payload|

      # just because in the future payload will have more data
      handle = payload

      puts "Incoming request for payload: #{payload}"

      brand = Brand.by_twitter(handle)
      if brand

        puts "Request for brand: #{brand.name}"

        # organize where to put the tweets
        tweet_group = {}
        brand.tweets.each do |t|
          group = (t.time.to_f / 60.minutes).round * 60.minutes
          (tweet_group[group] ||= []) << t
        end

        tweet_group.each do |group, tweets|
          command = "python #{cwd}/text_analyzer.py #{tweets.collect { |tweet| "\"#{preprocess_tweet(tweet.body)}\"" }.join(' ')}"
          output = `#{command}`.chomp

          begin # handles JSON parse exception
            result = JSON.parse(output)
            puts "Processing for #{handle}: #{tweets.size} tweets Sentiment: #{output} Average Sentiment/Tweet: #{result['score'].to_f / tweets.length}"
            # sentiment rows are unique by brand, timestamp
            @check = brand.sentiments.where({ timestamp: group }).first
            if @check
              # finished analyzing this batch
              brand.remove_tweets(tweets) if @check.update_attributes({
                                               num_tweets: tweets.size + @check.num_tweets,
                                               normalized_total_score: result['normalized_score'].to_i + @check.normalized_total_score,
                                               total_score: result['score'].to_i + @check.total_score,
                                               num_positive: result['num_positive'] + @check.num_positive,
                                               num_negative: result['num_negative'] + @check.num_negative })
            else
              # finished analyzing this batch
              brand.remove_tweets(tweets) if brand.sentiments << Sentiment.new({
                                                                   timestamp: group, 
                                                                   num_tweets: tweets.size,
	          	  		                           total_score: result['score'], 
	          	  		                           normalized_total_score: result['normalized_score'], 
	          			                           num_positive: result['num_positive'], 
	          			                           num_negative: result['num_negative'] })
            end
          rescue Exception => e
            puts e.message
	    puts e.backtrace.inspect
            puts "Failed to parse #{output}"
          end
        end

        # it's over!
        brand.finished_analyzing!

        # let the broker know we finished
        metadata.ack

      # didn't find a brand
      else
        puts 'No brand found'
        # will tell the broker to discard the message completely
        metadata.reject 
      end

      puts "Finished processing payload: #{payload}"
    end
  end
end
